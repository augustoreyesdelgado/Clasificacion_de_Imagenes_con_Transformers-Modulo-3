{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1EWMTx23LtE"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5ePSznv3Xbs"
      },
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WyoK7C553eaW"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "import os\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUi4e3gj3ghU"
      },
      "outputs": [],
      "source": [
        "# Configura el generador de imágenes\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=40,  # Permite rotar las imágenes hasta 40 grados\n",
        "    width_shift_range=0.2,  # Desplaza horizontalmente las imágenes hasta un 20% del ancho\n",
        "    height_shift_range=0.2,  # Desplaza verticalmente las imágenes hasta un 20% de la altura\n",
        "    shear_range=0.2,  # Aplica una transformación de corte (shear) hasta un 20%\n",
        "    zoom_range=0.2,  # Permite un zoom de hasta un 20% hacia adentro o hacia afuera\n",
        "    horizontal_flip=True,  # Invierte horizontalmente las imágenes\n",
        "    fill_mode='nearest'  # Rellena los nuevos píxeles utilizando el valor más cercano\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ZJFqZkt3p5K"
      },
      "outputs": [],
      "source": [
        "# Rutas de origen y destino\n",
        "dataset_dir = '/content/drive/MyDrive/mascotas'  # Ruta principal del dataset\n",
        "augmented_dir = '/content/mascotas-DA-alt'  # Ruta para las imágenes aumentadas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3ztTw0M3hb4"
      },
      "outputs": [],
      "source": [
        "train_generator = datagen.flow_from_directory(\n",
        "    dataset_dir,\n",
        "    target_size=(300,300),  # Tamaño de destino de las imágenes\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QK-gE5II3iq6"
      },
      "outputs": [],
      "source": [
        "array_to_img(train_generator[0][0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GnN8C7Pt4Qus"
      },
      "outputs": [],
      "source": [
        "def augment_images(src_dir, dest_dir):\n",
        "    # Recorre las carpetas de conjuntos (test, validation, train)\n",
        "    for subset in os.listdir(src_dir):\n",
        "        subset_path = os.path.join(src_dir, subset)\n",
        "\n",
        "        if os.path.isdir(subset_path):  # Verifica que sea un directorio\n",
        "            # Crea el directorio correspondiente en el destino\n",
        "            dest_subset_path = os.path.join(dest_dir, subset)\n",
        "            os.makedirs(dest_subset_path, exist_ok=True)\n",
        "\n",
        "            # Solo aplica aumento de datos si es la carpeta 'train'\n",
        "            if subset == 'train':\n",
        "                # Recorre las carpetas de clases dentro del conjunto\n",
        "                for class_name in os.listdir(subset_path):\n",
        "                    class_path = os.path.join(subset_path, class_name)\n",
        "\n",
        "                    if os.path.isdir(class_path):  # Asegúrate de procesar solo carpetas de clases\n",
        "                        os.makedirs(os.path.join(dest_subset_path, class_name), exist_ok=True)\n",
        "                        for img_name in os.listdir(class_path):\n",
        "                            img_path = os.path.join(class_path, img_name)\n",
        "                            if img_name.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
        "                                img = tf.keras.preprocessing.image.load_img(img_path)\n",
        "                                img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "                                img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "                                # Generar y guardar imágenes aumentadas\n",
        "                                i = 0\n",
        "                                # Cambia el número de imágenes a generar para la clase 'parrots'\n",
        "                                num_images_to_generate = 15 if class_name.lower() == 'parrots' else 3\n",
        "\n",
        "                                for batch in datagen.flow(img_array, batch_size=1,\n",
        "                                                          save_to_dir=os.path.join(dest_subset_path, class_name),\n",
        "                                                          save_prefix='aug', save_format='jpeg'):\n",
        "                                    i += 1\n",
        "                                    if i >= num_images_to_generate:  # Genera el número especificado de imágenes\n",
        "                                        break\n",
        "                                print(f\"Generadas {i} imágenes aumentadas para {img_name} en {class_name}/{subset}\")\n",
        "\n",
        "            else:\n",
        "                # Para las carpetas 'test' y 'validation', simplemente copia las imágenes\n",
        "                for class_name in os.listdir(subset_path):\n",
        "                    class_path = os.path.join(subset_path, class_name)\n",
        "                    if os.path.isdir(class_path):\n",
        "                        os.makedirs(os.path.join(dest_subset_path, class_name), exist_ok=True)\n",
        "                        for img_name in os.listdir(class_path):\n",
        "                            img_path = os.path.join(class_path, img_name)\n",
        "                            if img_name.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
        "                                # Copia las imágenes sin aumentarlas\n",
        "                                tf.keras.preprocessing.image.save_img(\n",
        "                                    os.path.join(dest_subset_path, class_name, img_name),\n",
        "                                    tf.keras.preprocessing.image.img_to_array(tf.keras.preprocessing.image.load_img(img_path))\n",
        "                                )\n",
        "                                print(f\"Copiada imagen {img_name} en {class_name}/{subset}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9yKaXOo4SHc"
      },
      "outputs": [],
      "source": [
        "# Ejecuta la función\n",
        "augment_images(dataset_dir, augmented_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hvXiR4r4TMw"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_VbEC2X04WRm"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset, DatasetDict\n",
        "\n",
        "# Cargar las divisiones del dataset\n",
        "train_dataset = load_dataset(\"imagefolder\", data_dir='/content/drive/MyDrive/mascotas', split=\"train\")\n",
        "val_dataset = load_dataset(\"imagefolder\", data_dir='/content/drive/MyDrive/mascotas', split=\"validation\")\n",
        "test_dataset = load_dataset(\"imagefolder\", data_dir='/content/drive/MyDrive/mascotas', split=\"test\")\n",
        "\n",
        "# Combinar las divisiones en un DatasetDict\n",
        "dataset = DatasetDict({\n",
        "    'train': train_dataset,\n",
        "    'validation': val_dataset,\n",
        "    'test': test_dataset\n",
        "})\n",
        "\n",
        "# Subir el dataset completo a Hugging Face\n",
        "dataset.push_to_hub(\"AugustoReies/mascotas-DA-alt\") # Recuerden cambiarlo por su cuenta de Hugging Face"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
